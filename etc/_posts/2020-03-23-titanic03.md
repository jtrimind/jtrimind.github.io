---

title:  "Titanic 문제 - 결측값, 랜덤 포레스트"
---

## 결측값(Missing Value)이란?
결측값은 측정한 값이 없다는 것이다.  
결측값을 삭제하거나, 대체함으로써 처리한다.

## 결측값 찾기
```python
train.info()
```
```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
PassengerId    891 non-null int64
Survived       891 non-null int64
Pclass         891 non-null int64
Name           891 non-null object
Sex            891 non-null object
Age            714 non-null float64
SibSp          891 non-null int64
Parch          891 non-null int64
Ticket         891 non-null object
Fare           891 non-null float64
Cabin          204 non-null object
Embarked       889 non-null object
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB
```
`pandas.DataFrame.info()`는 DataFrame의 간단한 요약을 보여준다.  
train의 891개 데이터 중 Age, Cabin, Embarked에 결측값이 존재한다.

```python
test.info()
```
```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 418 entries, 0 to 417
Data columns (total 11 columns):
PassengerId    418 non-null int64
Pclass         418 non-null int64
Name           418 non-null object
Sex            418 non-null object
Age            332 non-null float64
SibSp          418 non-null int64
Parch          418 non-null int64
Ticket         418 non-null object
Fare           417 non-null float64
Cabin          91 non-null object
Embarked       418 non-null object
dtypes: float64(2), int64(4), object(5)
memory usage: 36.0+ KB
```
test의 418개 데이터 중 Age, Fare, Cabin에 결측값이 존재한다.

## 결측값 삭제
```python
train = train.drop(['Name', 'Age', 'Cabin', 'Ticket', 'Fare'], axis=1)
test = test.drop(['Name', 'Age', 'Cabin', 'Ticket', 'Fare'], axis=1)
```
결측값이 존재하는 `Age`, `Cabin`, `Fare`를 삭제하였다.  
`Name`, `Ticket`은 분석에 사용하지 않을 것이라 삭제하였다.

## 결측값 대체
```python
train['Embarked'].value_counts()
```
```
S    644
C    168
Q     77
Name: Embarked, dtype: int64
```
train 데이터 중 `Embarked`의 값이 null인 경우는 2건이 존재한다.  
결측값을 가장 많은 빈도의 값으로 대체한다.

```python
train.loc[train['Embarked'].isnull(), 'Embarked'] = 'S'
```

## 랜덤 포레스트 적용
### 데이터 전처리
```python
train['Embarked'] = train['Embarked'].map({'S':0, 'C':1, 'Q':2})
test['Embarked'] = test['Embarked'].map({'S':0, 'C':1, 'Q':2})
train['Sex'] = train['Sex'].map({'male':0, 'female':1})
test['Sex'] = test['Sex'].map({'male':0, 'female':1})
```
문자열 데이터를 정수형 데이터로 변환하였다.

```python
train_x = train.drop(['PassengerId', 'Survived'], axis=1)
train_y = train['Survived']
test_x = test.drop('PassengerId', axis=1)
```
`Pclass`, `Sex`, `SibSp`, `Parch`, `Embarked`을 입력으로 받아 `Survived`를 예측하게 된다.  

### 랜덤 포레스트
```python
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()
rf.fit(train_x, train_y)
test_y = rf.predict(test_x)
```
train_x, train_y를 이용하여 학습한 후, test_x에 대해서 예측한다.

### 제출 데이터 생성
```python
submission = pd.DataFrame({
    'PassengerId' : test['PassengerId'],
    'Survived' : test_y
})
submission.to_csv('rf.csv', index=None)
```

## 제출
0.75119점으로 성별만 이용하여 예측하는 것보다 1%p 낮은 결과를 얻었다.  
데이터 처리나, 학습 방법을 조정하지 않으면 단순 예측보다 낮은 성능을 얻을 수도 있다.

## 정리
- 결측값을 찾고 기초적으로 처리하는 방법을 배웠다.
- random forest를 간단히 사용하는 법을 배웠다.
